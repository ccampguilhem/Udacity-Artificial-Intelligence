{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A First NN with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(n_features, n_labels):\n",
    "    \"\"\"\n",
    "    Return TensorFlow weights\n",
    "    :param n_features: Number of features\n",
    "    :param n_labels: Number of labels\n",
    "    :return: TensorFlow weights\n",
    "    \"\"\"\n",
    "    # TODO: Return weights\n",
    "    return tf.Variable(tf.truncated_normal((n_features, n_labels)))\n",
    "\n",
    "\n",
    "def get_biases(n_labels):\n",
    "    \"\"\"\n",
    "    Return TensorFlow bias\n",
    "    :param n_labels: Number of labels\n",
    "    :return: TensorFlow bias\n",
    "    \"\"\"\n",
    "    # TODO: Return biases\n",
    "    return tf.Variable(tf.zeros(n_labels))\n",
    "\n",
    "\n",
    "def linear(x, w, b):\n",
    "    \"\"\"\n",
    "    Return linear function in TensorFlow\n",
    "    :param x: TensorFlow input\n",
    "    :param w: TensorFlow weights\n",
    "    :param b: TensorFlow biases\n",
    "    :return: TensorFlow linear function\n",
    "    \"\"\"\n",
    "    # TODO: Linear Function (xW + b)\n",
    "    return tf.add(tf.matmul(x, w), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "def mnist_features_labels(n_images):\n",
    "    \"\"\"\n",
    "    Gets the first <n> images from the MNIST dataset\n",
    "    \"\"\"\n",
    "    mnist_features = []\n",
    "    mnist_labels = []\n",
    "\n",
    "    (train_images, train_labels), (test_images, test_labels) = tensorflow.keras.datasets.mnist.load_data(\n",
    "        \"/files/cedric/datasets/udacity/ai_nanodegree/keras/mnist.npz\")\n",
    "    return train_images[:n_images], train_labels[:n_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (3000, 784)\n",
      "Training labels: (3000, 10)\n",
      "Weights: [[ 0.6787582  -1.2905476   0.6214981  ...  0.48339772  1.2747914\n",
      "  -0.01603448]\n",
      " [-0.9859469  -0.399022   -1.7417542  ...  0.00939312 -1.7442837\n",
      "  -1.4343872 ]\n",
      " [-0.18266691  0.90518856 -1.155956   ...  0.18102506 -0.3362695\n",
      "   0.7481656 ]\n",
      " ...\n",
      " [ 0.08557525 -0.7461949  -1.882338   ...  0.61448115  0.15438998\n",
      "   0.17757855]\n",
      " [-1.5639133   1.6744155  -0.99645007 ...  0.11416566 -1.0038403\n",
      "  -1.9880397 ]\n",
      " [-0.00381211  1.1821641   0.39499584 ... -0.25230223 -0.37227023\n",
      "   0.33113402]]\n",
      "Bias: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Scores: [[16.328829    4.712735    2.7264004  ...  6.999519   -7.239559\n",
      "   2.559429  ]\n",
      " [ 8.809252    5.3128924   3.5760145  ... -2.3985395   1.5232508\n",
      "   8.879604  ]\n",
      " [ 4.536334   11.744574    4.743947   ... -2.3882246   9.551402\n",
      "   6.8786926 ]\n",
      " ...\n",
      " [ 7.3082523  -0.06698036  0.34979057 ... -5.1417737  -1.2566295\n",
      "  -9.489924  ]\n",
      " [ 0.7098668  -7.9925876  -4.989726   ... -1.5577829  -3.8732154\n",
      "   3.6981573 ]\n",
      " [ 8.796636    0.7308674  11.381304   ... -0.8118988   0.24560237\n",
      "  -1.5424101 ]]\n",
      "Softmax: [[7.6350993e-01 6.8866707e-06 9.4483300e-07 ... 6.7787107e-05\n",
      "  4.4380669e-11 7.9954032e-07]\n",
      " [6.5729576e-03 1.9920996e-04 3.5074765e-05 ... 8.9182343e-08\n",
      "  4.5028833e-06 7.0520365e-03]\n",
      " [6.6055247e-04 8.9208454e-01 8.1296626e-04 ... 6.4954577e-07\n",
      "  9.9523060e-02 6.8735443e-03]\n",
      " ...\n",
      " [2.0120242e-01 1.2606959e-04 1.9125450e-04 ... 7.8823513e-07\n",
      "  3.8366492e-05 1.0192440e-08]\n",
      " [4.8110502e-05 7.9948865e-09 1.6104168e-07 ... 4.9820969e-06\n",
      "  4.9184996e-07 9.5507636e-04]\n",
      " [2.8838078e-02 9.0583208e-06 3.8236088e-01 ... 1.9365675e-06\n",
      "  5.5757059e-06 9.3277282e-07]]\n",
      "Cross-Entropy: [11.874383   5.0247912 23.593721  ... 18.401619  18.644464  17.677551 ]\n",
      "Loss: 11.244158744812012\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Number of features (28*28 image is 784 features)\n",
    "n_features = 784\n",
    "# Number of labels\n",
    "n_labels = 10\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32)\n",
    "labels = tf.placeholder(tf.float32)\n",
    "\n",
    "# Weights and Biases\n",
    "w = get_weights(n_features, n_labels)\n",
    "b = get_biases(n_labels)\n",
    "\n",
    "# Linear Function xW + b\n",
    "logits = linear(features, w, b)\n",
    "\n",
    "# Training data\n",
    "train_features, train_labels = mnist_features_labels(3000)\n",
    "train_features = train_features.reshape((3000, -1)) / 255. # reshape and normalize\n",
    "print(f\"Training features: {train_features.shape}\")\n",
    "train_labels = pd.get_dummies(train_labels).values\n",
    "print(f\"Training labels: {train_labels.shape}\")\n",
    "\n",
    "\n",
    "with tf.Session() as session:\n",
    "    # TODO: Initialize session variables\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Softmax\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "\n",
    "    # Cross entropy\n",
    "    # This quantifies how far off the predictions were.\n",
    "    # You'll learn more about this in future lessons.\n",
    "    cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
    "\n",
    "    # Training loss\n",
    "    # You'll learn more about this in future lessons.\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "    # Rate at which the weights are changed\n",
    "    # You'll learn more about this in future lessons.\n",
    "    learning_rate = 0.08\n",
    "\n",
    "    # Gradient Descent\n",
    "    # This is the method used to train the model\n",
    "    # You'll learn more about this in future lessons.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    # Run optimizer and get loss\n",
    "    outputs = session.run(\n",
    "        [optimizer, loss, cross_entropy, prediction, logits, w, b],\n",
    "        feed_dict={features: train_features, labels: train_labels})\n",
    "\n",
    "# Print loss\n",
    "print('Weights: {}'.format(outputs[5]))\n",
    "print('Bias: {}'.format(outputs[6]))\n",
    "print('Scores: {}'.format(outputs[4]))\n",
    "print('Softmax: {}'.format(outputs[3]))\n",
    "print('Cross-Entropy: {}'.format(outputs[2]))\n",
    "print('Loss: {}'.format(outputs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
